{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(449.99994, shape=(), dtype=float32)\n",
      "tf.Tensor(449.99994, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 06:45:51.826061: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-01 06:45:55.018227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 112 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:1d:00.0, compute capability: 7.5\n",
      "2022-03-01 06:45:55.019217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 112 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:1e:00.0, compute capability: 7.5\n",
      "2022-03-01 06:45:55.020027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 137 MB memory:  -> device: 2, name: NVIDIA TITAN RTX, pci bus id: 0000:40:00.0, compute capability: 7.5\n",
      "2022-03-01 06:45:55.020781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 137 MB memory:  -> device: 3, name: NVIDIA TITAN RTX, pci bus id: 0000:41:00.0, compute capability: 7.5\n",
      "2022-03-01 06:45:55.041020: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 112.56M (118030336 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "vxm info: mutual information loss is experimental\n"
     ]
    }
   ],
   "source": [
    "from TrainVoxelmorph import train_vxm_model\n",
    "from DataHandler import DataHandler\n",
    "import voxelmorph as vxm\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import vxmlosses\n",
    "import tensorflow as tf\n",
    "import pytorchlosses\n",
    "import torch\n",
    "import devLossOld\n",
    "\n",
    "batch_size = 8\n",
    "batch_size_val = 12\n",
    "epochs = 200\n",
    "steps = 100\n",
    "learning_rate = 0.001\n",
    "nb_features = [[16, 32, 32, 32], [32, 32, 32, 32, 32, 16, 16]]\n",
    "#nb_features = [[16,16,32,32],[32,32,16,16]]\n",
    "resampling = False\n",
    "dataset = 'synthetic'\n",
    "multi_gpu = True\n",
    "dh = DataHandler()\n",
    "if dataset == 'synthetic':\n",
    "    dh.get_synthetic_data(\n",
    "        fixed_path=\n",
    "        '/home/cschellenberger/datam2olie/synthetic/orig/t3/Synthetic_CT/',\n",
    "        moving_path=\n",
    "        '/home/cschellenberger/datam2olie/synthetic/orig/t1/Synthetic_MR/')\n",
    "elif dataset == 'L2R':\n",
    "    dh.get_synthetic_data(\n",
    "        fixed_path=\n",
    "        '/home/cschellenberger/Documents/L2R_Resampled/L2R_Task1_CT/',\n",
    "        moving_path=\n",
    "        '/home/cschellenberger/Documents/L2R_Resampled/L2R_Task1_MR/')\n",
    "elif dataset == 'mnist':\n",
    "    dh.get_mnist_data(select_number=5)\n",
    "else:\n",
    "    raise NotImplementedError(\n",
    "        f'{dataset} is not implemented yet please select one of the following losses [mnist, synthetic]'\n",
    "    )                                       \n",
    "\n",
    "nmiDev = vxm.losses.MutualInformation()\n",
    "nmiDevOld = devLossOld.MutualInformation()\n",
    "nmi = vxmlosses.NMI(bin_centers = np.linspace(0, 1, num=16), vol_size = (256, 256, 128))\n",
    "#nmiTorch = pytorchlosses.MutualInformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "import tensorflow.keras.backend as K\n",
    "moving_image_paths = dh.x_val\n",
    "fixed_image_paths = dh.y_val\n",
    "moving_image = sitk.ReadImage(moving_image_paths[0])\n",
    "fixed_image = sitk.ReadImage(fixed_image_paths[0])\n",
    "moving_image = sitk.GetArrayFromImage(moving_image)\n",
    "fixed_image = sitk.GetArrayFromImage(fixed_image)\n",
    "moving_image = moving_image.reshape((1, 256, 256, 128))\n",
    "fixed_image = fixed_image.reshape((1, 256, 256, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(-0.9707546, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.40738332, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nmiLoss = nmi.loss(moving_image, moving_image)\n",
    "print(K.sum(nmiLoss))\n",
    "nmiLoss = nmi.loss(moving_image, fixed_image)\n",
    "print(K.sum(nmiLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.9869835, shape=(), dtype=float32)\n",
      "tf.Tensor(-0.44396466, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "with tf.device('/cpu:0'):\n",
    "    nmiDevLoss = nmiDev.loss(moving_image, moving_image)\n",
    "    nmiDevLoss = tf.reduce_mean(nmiDevLoss, 1, keepdims=True)\n",
    "    print(K.sum(nmiDevLoss))\n",
    "    nmiDevLoss = nmiDev.loss(moving_image, fixed_image)\n",
    "    nmiDevLoss = tf.reduce_mean(nmiDevLoss, 1, keepdims=True)\n",
    "    print(K.sum(nmiDevLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9721)\n",
      "tensor(-0.4068)\n"
     ]
    }
   ],
   "source": [
    "moving_image_torch = torch.from_numpy(moving_image)\n",
    "fixed_image_torch = torch.from_numpy(fixed_image)\n",
    "nmiTorchLoss = nmiTorch.forward(moving_image_torch, moving_image_torch)\n",
    "print(nmiTorchLoss)\n",
    "nmiTorchLoss = nmiTorch.forward(moving_image_torch, fixed_image_torch)\n",
    "print(nmiTorchLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-129.84944, shape=(), dtype=float32)\n",
      "tf.Tensor(-129.84944, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nmiDevLossOld = nmiDevOld.loss(moving_image, moving_image)\n",
    "print(K.sum(nmiDevLossOld))\n",
    "nmiDevLoss = nmiDevOld.loss(moving_image, fixed_image)\n",
    "print(K.sum(nmiDevLossOld))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9debd726cb181d61f55789b752b213620e0e1fe4a35b9ad670b0d66a9542fcd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
